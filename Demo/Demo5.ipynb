{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f877cc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neurokit2 in c:\\users\\estya\\anaconda3\\lib\\site-packages (0.2.12)\n",
      "Requirement already satisfied: requests in c:\\users\\estya\\anaconda3\\lib\\site-packages (from neurokit2) (2.32.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\estya\\anaconda3\\lib\\site-packages (from neurokit2) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\estya\\anaconda3\\lib\\site-packages (from neurokit2) (2.3.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\estya\\anaconda3\\lib\\site-packages (from neurokit2) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\estya\\anaconda3\\lib\\site-packages (from neurokit2) (1.5.1)\n",
      "Requirement already satisfied: matplotlib>=3.5.0 in c:\\users\\estya\\anaconda3\\lib\\site-packages (from neurokit2) (3.9.2)\n",
      "Requirement already satisfied: PyWavelets>=1.4.0 in c:\\users\\estya\\anaconda3\\lib\\site-packages (from neurokit2) (1.7.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\estya\\anaconda3\\lib\\site-packages (from matplotlib>=3.5.0->neurokit2) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\estya\\anaconda3\\lib\\site-packages (from matplotlib>=3.5.0->neurokit2) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\estya\\anaconda3\\lib\\site-packages (from matplotlib>=3.5.0->neurokit2) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\estya\\anaconda3\\lib\\site-packages (from matplotlib>=3.5.0->neurokit2) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\estya\\anaconda3\\lib\\site-packages (from matplotlib>=3.5.0->neurokit2) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\estya\\anaconda3\\lib\\site-packages (from matplotlib>=3.5.0->neurokit2) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\estya\\anaconda3\\lib\\site-packages (from matplotlib>=3.5.0->neurokit2) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\estya\\anaconda3\\lib\\site-packages (from matplotlib>=3.5.0->neurokit2) (2.9.0.post0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\estya\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->neurokit2) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\estya\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->neurokit2) (3.5.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\estya\\anaconda3\\lib\\site-packages (from pandas->neurokit2) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\estya\\anaconda3\\lib\\site-packages (from pandas->neurokit2) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\estya\\anaconda3\\lib\\site-packages (from requests->neurokit2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\estya\\anaconda3\\lib\\site-packages (from requests->neurokit2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\estya\\anaconda3\\lib\\site-packages (from requests->neurokit2) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\estya\\anaconda3\\lib\\site-packages (from requests->neurokit2) (2025.4.26)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\estya\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->neurokit2) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install neurokit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f94cc22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import ast\n",
    "import neurokit2 as nk\n",
    "from wfdb import processing \n",
    "from scipy.signal import butter, filtfilt, welch\n",
    "from scipy.stats import skew, kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2525563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# 1. Load Metadata\n",
    "# ------------------------------\n",
    "BASE_PATH = \"Dataset/ptbxl/\"\n",
    "\n",
    "df_meta = pd.read_csv(BASE_PATH + \"ptbxl_database.csv\")\n",
    "df_meta['scp_codes'] = df_meta['scp_codes'].apply(ast.literal_eval)\n",
    "agg_df = pd.read_csv(BASE_PATH + \"scp_statements.csv\", index_col=0)\n",
    "agg_df = agg_df[agg_df['diagnostic'] == 1]\n",
    "superclasses = ['NORM', 'MI', 'STTC', 'CD', 'HYP']\n",
    "\n",
    "def get_superclass(scp_dict):\n",
    "    classes = [agg_df.loc[code]['diagnostic_class'] for code in scp_dict if code in agg_df.index]\n",
    "    classes = [c for c in classes if c in superclasses]\n",
    "    return classes[0] if classes else 'OTHER'\n",
    "\n",
    "df_meta['label'] = df_meta['scp_codes'].apply(get_superclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c6997b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------\n",
    "# 2. Preprocessing and Filters\n",
    "# ------------------------------\n",
    "def bandpass_filter(signal, fs=500, low=0.5, high=40):\n",
    "    nyq = 0.5 * fs\n",
    "    b, a = butter(4, [low / nyq, high / nyq], btype='band')\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "def preprocess_lead(lead_signal, fs=500):\n",
    "    filtered = bandpass_filter(lead_signal, fs)\n",
    "    filtered -= np.median(filtered)        # Baseline correction\n",
    "    return (filtered - np.mean(filtered)) / np.std(filtered)  # Normalize\n",
    "\n",
    "# ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c7d4bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Robust Fiducial Detection\n",
    "# ------------------------------\n",
    "def detect_rpeaks_wfdb(signal, fs=500):\n",
    "    \"\"\"Fallback R-peak detection using WFDB XQRS.\"\"\"\n",
    "    try:\n",
    "        xqrs = processing.XQRS(sig=signal, fs=fs)\n",
    "        xqrs.detect()\n",
    "        return np.array(xqrs.qrs_inds)\n",
    "    except:\n",
    "        return np.array([])\n",
    "\n",
    "def robust_delineation(signal, rpeaks, fs=500):\n",
    "    \"\"\"Try multiple NeuroKit2 delineation methods.\"\"\"\n",
    "    for method in [\"dwt\", \"cwt\", \"peaks\"]:\n",
    "        try:\n",
    "            d = nk.ecg_delineate(signal, rpeaks=rpeaks, sampling_rate=fs, method=method)\n",
    "            if isinstance(d, dict) and any(len(v) > 0 for v in d.values()):\n",
    "                return d\n",
    "        except:\n",
    "            continue\n",
    "    return {}\n",
    "\n",
    "def detect_fiducials(signal, fs=500):\n",
    "    \"\"\"Hybrid approach: WFDB for R-peaks + NeuroKit2 for delineation.\"\"\"\n",
    "    try:\n",
    "        _, info = nk.ecg_process(signal, sampling_rate=fs)\n",
    "        rpeaks = info[\"ECG_R_Peaks\"]\n",
    "    except:\n",
    "        rpeaks = detect_rpeaks_wfdb(signal, fs)\n",
    "    d = robust_delineation(signal, rpeaks, fs)\n",
    "    return rpeaks, d\n",
    "\n",
    "# ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "579d70bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Helper Functions\n",
    "# ------------------------------\n",
    "def safe_get(d, key):\n",
    "    \"\"\"Safely extract a list of indices from delineation dict.\"\"\"\n",
    "    return [int(x) for x in d.get(key, []) if not np.isnan(x)] if key in d else []\n",
    "\n",
    "def zero_crossings(signal):\n",
    "    return ((signal[:-1] * signal[1:]) < 0).sum()\n",
    "\n",
    "def compute_area(signal, start_idx, end_idx):\n",
    "    if start_idx is None or end_idx is None or end_idx <= start_idx:\n",
    "        return np.nan\n",
    "    return np.trapz(np.abs(signal[start_idx:end_idx]))\n",
    "\n",
    "def compute_slope(signal, idx1, idx2):\n",
    "    if idx1 is None or idx2 is None or idx2 <= idx1:\n",
    "        return np.nan\n",
    "    return (signal[idx2] - signal[idx1]) / (idx2 - idx1)\n",
    "\n",
    "def measure_st_elevation(signal, j_point, fs=500):\n",
    "    if j_point is None: return np.nan\n",
    "    idx = int(j_point + 0.08 * fs)\n",
    "    baseline = np.mean(signal[:int(0.2 * fs)])\n",
    "    return signal[idx] - baseline if idx < len(signal) else np.nan\n",
    "\n",
    "# ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea27d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# 5. Feature Extraction per Lead\n",
    "# ------------------------------\n",
    "def extract_lead_features(lead_signal, fs=500):\n",
    "    features = {}\n",
    "    try:\n",
    "        rpeaks, d = detect_fiducials(lead_signal, fs)\n",
    "        rr_intervals = np.diff(rpeaks) / fs * 1000\n",
    "\n",
    "        # Fiducial arrays\n",
    "        q_on, s_off = safe_get(d, 'ECG_Q_Onsets'), safe_get(d, 'ECG_S_Offsets')\n",
    "        p_on, t_off = safe_get(d, 'ECG_P_Onsets'), safe_get(d, 'ECG_T_Offsets')\n",
    "        t_on, t_peaks = safe_get(d, 'ECG_T_Onsets'), safe_get(d, 'ECG_T_Peaks')\n",
    "        r_pk = safe_get(d, 'ECG_R_Peaks')\n",
    "\n",
    "        # --- TIME DOMAIN ---\n",
    "        features['RR_mean'] = np.nanmean(rr_intervals) if len(rr_intervals) else np.nan\n",
    "        features['RR_std'] = np.nanstd(rr_intervals) if len(rr_intervals) else np.nan\n",
    "        features['HR'] = 60000 / features['RR_mean'] if features['RR_mean'] else np.nan\n",
    "        features['QRS_duration'] = np.nanmean([(s - q)/fs*1000 for q, s in zip(q_on, s_off) if s > q]) if q_on and s_off else np.nan\n",
    "        features['PR_interval'] = np.nanmean([(q - p)/fs*1000 for p, q in zip(p_on, q_on) if q > p]) if p_on and q_on else np.nan\n",
    "        features['QT_interval'] = np.nanmean([(t - q)/fs*1000 for q, t in zip(q_on, t_off) if t > q]) if q_on and t_off else np.nan\n",
    "        features['T_duration'] = np.nanmean([(tf - to)/fs*1000 for to, tf in zip(t_on, t_off) if tf > to]) if t_on and t_off else np.nan\n",
    "\n",
    "        # --- MORPHOLOGICAL ---\n",
    "        features['R_amp'] = np.nanmax(lead_signal)\n",
    "        features['S_amp'] = np.nanmin(lead_signal)\n",
    "        features['R_S_ratio'] = features['R_amp'] / abs(features['S_amp']) if features['S_amp'] != 0 else np.nan\n",
    "        features['Q_amp'] = np.nanmean([lead_signal[q] for q in q_on if q < len(lead_signal)]) if q_on else np.nan\n",
    "        features['Q_duration'] = np.nanmean([(r - q)/fs*1000 for q, r in zip(q_on, r_pk) if r > q]) if q_on and r_pk else np.nan\n",
    "        features['QRS_area'] = np.nanmean([compute_area(lead_signal, q, s) for q, s in zip(q_on, s_off) if s > q]) if q_on and s_off else np.nan\n",
    "\n",
    "        # T-wave\n",
    "        if t_peaks:\n",
    "            t_amps = [lead_signal[t] for t in t_peaks if t < len(lead_signal)]\n",
    "            features['T_amp'] = np.nanmean(t_amps)\n",
    "            features['T_polarity'] = np.nanmean([np.sign(a) for a in t_amps])\n",
    "            features['T_inversion'] = 1 if np.nanmean(t_amps) < 0 else 0\n",
    "        else:\n",
    "            features['T_amp'] = features['T_polarity'] = features['T_inversion'] = np.nan\n",
    "\n",
    "        if t_on and t_off:\n",
    "            t_asym = []\n",
    "            for to, tf in zip(t_on, t_off):\n",
    "                if tf > to:\n",
    "                    mid = (to + tf) // 2\n",
    "                    su, sd = compute_slope(lead_signal, to, mid), compute_slope(lead_signal, mid, tf)\n",
    "                    if sd != 0: t_asym.append(su / abs(sd))\n",
    "            features['T_asymmetry'] = np.nanmean(t_asym) if t_asym else np.nan\n",
    "\n",
    "        # ST elevation\n",
    "        features['ST_elevation'] = np.nanmean([measure_st_elevation(lead_signal, j, fs) for j in s_off]) if s_off else np.nan\n",
    "\n",
    "        # --- FREQUENCY ---\n",
    "        f, Pxx = welch(lead_signal, fs, nperseg=1024)\n",
    "        bands = {'VLF': (0, 0.5), 'LF': (0.5, 4), 'MF': (4, 15), 'HF': (15, 40)}\n",
    "        for b, (lo, hi) in bands.items():\n",
    "            features[f'{b}_power'] = np.trapz(Pxx[(f >= lo) & (f <= hi)], f[(f >= lo) & (f <= hi)])\n",
    "        features['LF_HF_ratio'] = features['LF_power'] / features['HF_power'] if features.get('HF_power', 0) > 0 else np.nan\n",
    "        features['dominant_freq'] = f[np.argmax(Pxx)]\n",
    "        Pxx_norm = Pxx / np.sum(Pxx)\n",
    "        features['spectral_entropy'] = -np.sum(Pxx_norm * np.log2(Pxx_norm + 1e-10))\n",
    "\n",
    "        # --- STATISTICAL ---\n",
    "        features['mean'] = np.mean(lead_signal)\n",
    "        features['median'] = np.median(lead_signal)\n",
    "        features['std'] = np.std(lead_signal)\n",
    "        features['skew'] = skew(lead_signal)\n",
    "        features['kurt'] = kurtosis(lead_signal)\n",
    "        features['zero_crossings'] = zero_crossings(lead_signal)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Feature extraction failed: {e}\")\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Load ECG Signal Function\n",
    "# ------------------------------\n",
    "def load_ecg(record_row):\n",
    "    \"\"\"Load ECG signal using WFDB\"\"\"\n",
    "    rec_path = BASE_PATH + record_row['filename_hr']  # uses high-resolution 500Hz files\n",
    "    sig, fields = wfdb.rdsamp(rec_path)\n",
    "    return sig, fields['fs'], fields['sig_name']\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b9dc2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing ECG 1...\n",
      "[INFO] Processing ECG 2...\n",
      "[INFO] Processing ECG 3...\n",
      "[INFO] Processing ECG 4...\n",
      "[INFO] Processing ECG 5...\n",
      "[INFO] Processing ECG 6...\n",
      "[INFO] Processing ECG 7...\n",
      "[INFO] Processing ECG 8...\n",
      "[INFO] Processing ECG 9...\n",
      "[INFO] Processing ECG 10...\n",
      "[INFO] Feature extraction (10 records) completed! Saved to ecg_features_test10.csv\n"
     ]
    }
   ],
   "source": [
    "# 6. Process Each ECG Record\n",
    "# ------------------------------\n",
    "def extract_record_features(record_row):\n",
    "    sig, fs, leads = load_ecg(record_row)\n",
    "    record_features = {}\n",
    "    for i, lead in enumerate(leads):\n",
    "        lead_sig = preprocess_lead(sig[:, i])\n",
    "        lead_feats = extract_lead_features(lead_sig, fs)\n",
    "        for k, v in lead_feats.items():\n",
    "            record_features[f'{lead}_{k}'] = v\n",
    "    record_features['label'] = record_row['label']\n",
    "    record_features['ecg_id'] = record_row['ecg_id']\n",
    "    return record_features\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 7. Run for 10 Rows\n",
    "# ------------------------------\n",
    "all_features = []\n",
    "for idx, row in df_meta.head(10).iterrows():\n",
    "    print(f\"[INFO] Processing ECG {row['ecg_id']}...\")\n",
    "    feats = extract_record_features(row)\n",
    "    all_features.append(feats)\n",
    "\n",
    "df_features = pd.DataFrame(all_features)\n",
    "df_features.to_csv(\"ecg_features_test10.csv\", index=False)\n",
    "print(\"[INFO] Feature extraction (10 records) completed! Saved to ecg_features_test10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dca33bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     I_RR_mean   I_RR_std       I_HR  I_QRS_duration  I_PR_interval  \\\n",
      "0   940.000000  16.329932  63.829787             NaN            NaN   \n",
      "1  1258.285714  76.691803  47.683924             NaN            NaN   \n",
      "2   940.444444  18.349151  63.799622             NaN            NaN   \n",
      "3   800.727273  43.386405  74.931880             NaN            NaN   \n",
      "4   905.200000  48.647302  66.283694             NaN            NaN   \n",
      "\n",
      "   I_QT_interval  I_T_duration   I_R_amp   I_S_amp  I_R_S_ratio  ...  \\\n",
      "0            NaN           NaN  6.603620 -1.182941     5.582374  ...   \n",
      "1            NaN           NaN  5.380209 -2.633852     2.042715  ...   \n",
      "2            NaN           NaN  6.793730 -1.477961     4.596692  ...   \n",
      "3            NaN           NaN  3.592486 -4.429590     0.811020  ...   \n",
      "4            NaN           NaN  5.604463 -3.159961     1.773586  ...   \n",
      "\n",
      "   V6_dominant_freq  V6_spectral_entropy       V6_mean  V6_median  V6_std  \\\n",
      "0          0.976562             4.791125 -2.415845e-17  -0.313975     1.0   \n",
      "1          0.976562             5.533735 -2.842171e-18  -0.220352     1.0   \n",
      "2          0.976562             5.536908  1.136868e-17  -0.267782     1.0   \n",
      "3          3.906250             5.510915  3.623768e-17  -0.241045     1.0   \n",
      "4          4.394531             5.492593 -1.136868e-17  -0.287592     1.0   \n",
      "\n",
      "    V6_skew    V6_kurt  V6_zero_crossings  label  ecg_id  \n",
      "0  2.655858   8.428877                 63   NORM       1  \n",
      "1  4.742766  28.905683                 42   NORM       2  \n",
      "2  4.147017  21.367669                 59   NORM       3  \n",
      "3  2.291942   8.570138                 51   NORM       4  \n",
      "4  4.338472  21.705119                 48   NORM       5  \n",
      "\n",
      "[5 rows x 362 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"ecg_features_test10.csv\")\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc1ac5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
